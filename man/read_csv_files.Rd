% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/read.R
\name{read_csv_files}
\alias{read_csv_files}
\title{Read CSV Files and Their Metadata}
\usage{
read_csv_files(
  provider,
  dataset,
  subdir = NULL,
  dir_data = NULL,
  metadata_dir = NULL,
  gcs_archive = NULL,
  gcs_bucket = "calcofi-files-public",
  archive_prefix = "archive",
  sync_archive = TRUE,
  verbose = FALSE,
  field_descriptions = NULL
)
}
\arguments{
\item{provider}{Data provider (e.g., "swfsc.noaa.gov")}

\item{dataset}{Dataset name (e.g., "calcofi-db")}

\item{subdir}{Optional subdirectory (i.e.,
{dir_data}/{provider}/{dataset}/{subdir}) for CSV files. Use for datasets
organized with \verb{raw/} or \verb{derived/} subdirectories.}

\item{dir_data}{Directory path of CalCOFI base data folder available locally,
with CSVs under {provider}/{dataset} directory. If NULL and gcs_archive
is also NULL, will error. Set to NULL to use gcs_archive instead.}

\item{metadata_dir}{Directory containing redefinition metadata files
(tbls_redefine.csv, flds_redefine.csv). The directory should be structured
as {metadata_dir}/{provider}/{dataset}/. If NULL, falls back to the
legacy location in calcofi4db/inst/ingest/ (deprecated).}

\item{gcs_archive}{GCS archive path to read from (for reproducibility).
Can be either a timestamp (e.g., "2026-02-02_121557") or full path
(e.g., "gs://calcofi-files-public/archive/2026-02-02_121557").
If provided, downloads from archive instead of using local files.}

\item{gcs_bucket}{GCS bucket for archives (default: "calcofi-files-public")}

\item{archive_prefix}{Prefix for archive folder (default: "archive")}

\item{sync_archive}{Whether to sync local files to GCS archive (default: TRUE).
Only applies when using dir_data (local files).}

\item{verbose}{Print detailed messages. Default: FALSE}

\item{field_descriptions}{Named list of CSV file paths containing field
metadata for auto-populating descriptions and units in the generated
\code{flds_redefine.csv}. See \code{\link[=create_redefinition_files]{create_redefinition_files()}} for details.
Default: NULL.}
}
\value{
A list containing:
\describe{
\item{d_csv}{List with CSV data including:
- data: tibble with columns (tbl, csv, file_size, last_modified,
data, nrow, ncol, flds, gcs_path)
- tables: summary of tables (tbl, nrow, ncol)
- fields: summary of fields (tbl, fld, type)}
\item{source_files}{Data frame for provenance tracking with columns:
table, local_path, gcs_path, file_size, last_modified, nrow, ncol}
\item{d_tbls_rd}{Table redefinition data frame with columns:
tbl_old, tbl_new, tbl_description}
\item{d_flds_rd}{Field redefinition data frame with columns:
tbl_old, tbl_new, fld_old, fld_new, order_old, order_new,
type_old, type_new, fld_description, notes, mutation}
\item{paths}{List of file paths used in the workflow}
}
}
\description{
Reads CSV files from a directory or GCS archive and prepares them for
ingestion into a database. This function is the primary entry point for
the CalCOFI data ingestion workflow. It performs the following steps:
}
\details{
\enumerate{
\item Reads CSV files from local directory or downloads from GCS archive
\item If using local files, syncs to GCS archive for immutable provenance
\item Extracts metadata about tables and fields from the CSV files
\item Creates or reads redefinition files for table and field transformations
}

The function returns a comprehensive data structure containing:
\itemize{
\item Raw CSV data and metadata (d_csv)
\item Source files with provenance tracking (source_files)
\item Table redefinitions (d_tbls_rd) for renaming/describing tables
\item Field redefinitions (d_flds_rd) for renaming/typing/transforming fields
\item File paths used in the workflow
}
}
\examples{
\dontrun{
# Read from local Google Drive mount (syncs to GCS archive)
d <- read_csv_files(
  provider     = "swfsc.noaa.gov",
  dataset      = "calcofi-db",
  dir_data     = "~/My Drive/projects/calcofi/data-public",
  metadata_dir = "metadata")

# Read from specific GCS archive (for reproducibility)
d <- read_csv_files(
  provider     = "swfsc.noaa.gov",
  dataset      = "calcofi-db",
  gcs_archive  = "2026-02-02_121557",
  metadata_dir = "metadata")

# Access the raw CSV data
d$d_csv$data

# Check source file provenance
d$source_files
}
}
\concept{read}
